{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Simple Decision Tree using sklearn-like API\n",
    "class SimpleDecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2, max_features=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "    \n",
    "    def fit(self, X, y, depth=0):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        \n",
    "        # Stop conditions\n",
    "        if (depth >= self.max_depth or n_samples < self.min_samples_split \n",
    "                or self.n_classes == 1):\n",
    "            self.leaf_value = mode(y).mode[0]\n",
    "            return\n",
    "        \n",
    "        # Select random subset of features\n",
    "        if self.max_features is not None:\n",
    "            feats_idx = np.random.choice(n_features, self.max_features, replace=False)\n",
    "        else:\n",
    "            feats_idx = np.arange(n_features)\n",
    "        \n",
    "        # Find best split\n",
    "        best_feat, best_thresh, best_gain = None, None, -1\n",
    "        for feat in feats_idx:\n",
    "            thresholds = np.unique(X[:, feat])\n",
    "            for threshold in thresholds:\n",
    "                gain = self._information_gain(y, X[:, feat], threshold)\n",
    "                if gain > best_gain:\n",
    "                    best_feat, best_thresh, best_gain = feat, threshold, gain\n",
    "        \n",
    "        if best_gain == -1:\n",
    "            self.leaf_value = mode(y).mode[0]\n",
    "            return\n",
    "        \n",
    "        # Store best split parameters\n",
    "        self.feat_idx = best_feat\n",
    "        self.threshold = best_thresh\n",
    "\n",
    "        # Split data\n",
    "        left_idxs = X[:, best_feat] <= best_thresh\n",
    "        right_idxs = X[:, best_feat] > best_thresh\n",
    "\n",
    "        # Recursive building\n",
    "        self.left = SimpleDecisionTree(\n",
    "            max_depth=self.max_depth, \n",
    "            min_samples_split=self.min_samples_split,\n",
    "            max_features=self.max_features\n",
    "        )\n",
    "        self.left.fit(X[left_idxs], y[left_idxs], depth+1)\n",
    "\n",
    "        self.right = SimpleDecisionTree(\n",
    "            max_depth=self.max_depth, \n",
    "            min_samples_split=self.min_samples_split,\n",
    "            max_features=self.max_features\n",
    "        )\n",
    "        self.right.fit(X[right_idxs], y[right_idxs], depth+1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs) for inputs in X])\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        if hasattr(self, 'leaf_value'):\n",
    "            return self.leaf_value\n",
    "        if inputs[self.feat_idx] <= self.threshold:\n",
    "            return self.left._predict(inputs)\n",
    "        else:\n",
    "            return self.right._predict(inputs)\n",
    "    \n",
    "    def _entropy(self, y):\n",
    "        counts = np.bincount(y)\n",
    "        probabilities = counts / len(y)\n",
    "        return -np.sum([p * np.log2(p) for p in probabilities if p > 0])\n",
    "\n",
    "    def _information_gain(self, y, X_col, split_thresh):\n",
    "        parent_entropy = self._entropy(y)\n",
    "\n",
    "        left_idxs = X_col <= split_thresh\n",
    "        right_idxs = X_col > split_thresh\n",
    "        \n",
    "        if sum(left_idxs) == 0 or sum(right_idxs) == 0:\n",
    "            return 0\n",
    "        \n",
    "        n = len(y)\n",
    "        n_left, n_right = sum(left_idxs), sum(right_idxs)\n",
    "\n",
    "        e_left, e_right = self._entropy(y[left_idxs]), self._entropy(y[right_idxs])\n",
    "        child_entropy = (n_left / n) * e_left + (n_right / n) * e_right\n",
    "        \n",
    "        return parent_entropy - child_entropy\n",
    "\n",
    "\n",
    "# Random Forest classifier built from scratch\n",
    "class CustomRandomForest:\n",
    "    def __init__(self, n_estimators=10, max_depth=10, min_samples_split=2, max_features='sqrt', random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_features = max_features\n",
    "        self.trees = []\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.trees = []\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if self.max_features == 'sqrt':\n",
    "            max_features = int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            max_features = int(np.log2(n_features))\n",
    "        else:\n",
    "            max_features = n_features\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            idxs = np.random.choice(n_samples, n_samples, replace=True)\n",
    "            X_sample, y_sample = X[idxs], y[idxs]\n",
    "            tree = SimpleDecisionTree(\n",
    "                max_depth=self.max_depth, \n",
    "                min_samples_split=self.min_samples_split,\n",
    "                max_features=max_features\n",
    "            )\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        tree_preds = np.array([tree.predict(X) for tree in self.trees])\n",
    "        return mode(tree_preds, axis=0).mode[0]\n",
    "\n",
    "    def accuracy(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return np.mean(preds == y)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
