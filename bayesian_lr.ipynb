{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Logistic Regression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def log_likelihood(w, X, y):\n",
    "    z = np.dot(X, w)\n",
    "    # Clip values to avoid log(0) issues\n",
    "    sig = np.clip(sigmoid(z), 1e-10, 1 - 1e-10)\n",
    "    return np.sum(y * np.log(sig) + (1 - y) * np.log(1 - sig))\n",
    "\n",
    "\n",
    "def log_prior(w, tau):\n",
    "    return -0.5 * np.sum(w ** 2) / (tau ** 2)\n",
    "\n",
    "\n",
    "def log_posterior(w, X, y, tau):\n",
    "    return log_likelihood(w, X, y) + log_prior(w, tau)\n",
    "\n",
    "\n",
    "def grad_log_posterior(w, X, y, tau):\n",
    "    predictions = sigmoid(np.dot(X, w))\n",
    "    # Gradient from the likelihood and the prior\n",
    "    gradient = np.dot(X.T, (y - predictions)) - w / (tau ** 2)\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def gradient_ascent(X, y, tau, learning_rate=0.01, n_iter=1000):\n",
    "    # Initialize weights to zeros\n",
    "    w = np.zeros(X.shape[1])\n",
    "    for i in range(n_iter):\n",
    "        grad = grad_log_posterior(w, X, y, tau)\n",
    "        w += learning_rate * grad\n",
    "        # Optionally, print progress every 100 iterations\n",
    "        if (i+1) % 100 == 0:\n",
    "            current_lp = log_posterior(w, X, y, tau)\n",
    "            print(f\"Iteration {i+1}, Log-Posterior: {current_lp:.4f}\")\n",
    "    return w\n",
    "\n",
    "\n",
    "def predict_proba(X, w):\n",
    "    return sigmoid(np.dot(X, w))\n",
    "\n",
    "\n",
    "def predict(X, w, threshold=0.5):\n",
    "    probs = predict_proba(X, w)\n",
    "    return (probs >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"atp_matches_2010_2024_missing_handled.csv\")\n",
    "\n",
    "print(\"Dataset Head:\")\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "print(\"\\nColumns in Dataset:\")\n",
    "print(df.columns)\n",
    "\n",
    "target_column = \"match_winner\"  \n",
    "\n",
    "feature_columns = [col for col in df.columns if col != target_column]\n",
    "\n",
    "# Convert the DataFrame into NumPy arrays for use in our model functions.\n",
    "X = df[feature_columns].values\n",
    "y = df[target_column].values\n",
    "\n",
    "# Verifying the shapes of the feature matrix and target vector\n",
    "print(\"\\nFeature Matrix Shape:\", X.shape)\n",
    "print(\"Target Vector Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the BLR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "tau = 1.0\n",
    "learning_rate = 0.01\n",
    "n_iter = 1000\n",
    "\n",
    "# Train the model using gradient ascent\n",
    "w_est = gradient_ascent(X, y, tau, learning_rate, n_iter)\n",
    "print(\"Estimated weights:\", w_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = predict(X, w_est)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(\"Training Accuracy:\", accuracy)\n",
    "\n",
    "# Optional: Plot probabilities vs true labels\n",
    "probs_pred = predict_proba(X, w_est)\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(range(len(y)), probs_pred, label='Predicted Probabilities', alpha=0.7)\n",
    "plt.scatter(range(len(y)), y, label='True Labels', marker='x')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Probability / Label')\n",
    "plt.legend()\n",
    "plt.title('Predicted Probabilities vs True Labels')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
